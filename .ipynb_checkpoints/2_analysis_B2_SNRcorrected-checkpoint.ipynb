{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71d3cae3-efae-4887-8c28-02b239db3f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/lea/Documents/obsidian_notes/masterADS/ads_thesis_RIFT/my_code_expe2'\n",
    "data_file = '/data/B2/data.mat'\n",
    "epoch_file = '/data/B2/preprocessing/B2_EEG_epo.fif'\n",
    "\n",
    "relevant_electrodes = ['O2','PO4','PO8','P8','P4','P6','P2','P1','P3','P5','P7','PO7','PO3','O1','Pz','POz','Oz','Iz']\n",
    "\n",
    "# Dic to index trial_info matrix\n",
    "info_colnames = {'reaction_times':0,'reaction_err':1, 'answer':2,'base_delay':3,\\\n",
    "                      'target_timings':4, 'flicker_sides':5, 'cued_side':6, 'orients_L':7, 'orients_R':8,\\\n",
    "                      'angle_magnitude':9, 'probe_sides':10, 'targets_binary':12, 'attention_type_block':13,\\\n",
    "                      'trial_num_my_rec':14}\n",
    "info_colnumtonames = {v: k for k, v in info_colnames.items()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "973fb578-17ea-497c-b004-0248aacfff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "from mne.time_frequency import EpochsTFRArray\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d64563f-c5ae-4bc2-873e-734461f56e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /home/lea/Documents/obsidian_notes/masterADS/ads_thesis_RIFT/my_code_expe2/data/B2/preprocessing/B2_EEG_epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    2000.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "555 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 14 columns\n"
     ]
    }
   ],
   "source": [
    "f = sio.loadmat(f'{data_path}{data_file}')\n",
    "\n",
    "# Create pd df to pass to mne metadata\n",
    "pd_info = {}\n",
    "for i, column in enumerate(f['data'][0][0]):\n",
    "    if i in info_colnames.values():\n",
    "        # Remove practice trials\n",
    "        column = column[4:,:]\n",
    "        # Collapse to trial indexes\n",
    "        original_shape = column.shape\n",
    "        new_shape = (original_shape[0] * original_shape[1],) + original_shape[2:]\n",
    "        column = np.reshape(column, new_shape)\n",
    "        pd_info[info_colnumtonames[i]] = column\n",
    "pd_info = pd.DataFrame(pd_info, columns=info_colnames.keys())\n",
    "pd_info \n",
    "\n",
    "# Load eeg epochs .fif and add metadata\n",
    "epochs = mne.read_epochs(f'{data_path}{epoch_file}')\n",
    "epoch_good = [x for x,y in enumerate(epochs.drop_log) if len(y) == 0]\n",
    "epochs.metadata = pd_info.iloc[epoch_good]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eea844c7-1866-4875-8325-d20f5a939f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Number of events</th>\n",
       "        <td>555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Events</th>\n",
       "        \n",
       "        <td>3: 555</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Time range</th>\n",
       "        <td>-1.000 – 2.000 s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Baseline</th>\n",
       "        <td>-1.000 – 0.000 s</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<EpochsFIF |  555 events (all good), -1 – 2 s, baseline -1 – 0 s, ~468.4 MB, data loaded, with metadata,\n",
       " '3': 555>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only posterior electrodes\n",
    "epochs.pick_channels(relevant_electrodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9377463-1a5a-4297-a3bb-2fab4045a5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only trials where there was no target\n",
    "epochs = epochs['targets_binary==0']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f775e89-3e72-4e71-94fb-955ea46a9634",
   "metadata": {},
   "source": [
    "# A. Frequency tagging condition\n",
    "# 1 - Tag presence\n",
    "## 1.1 FFT & SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d453d56c-5b4c-4fd4-83e1-35cf20e7ac39",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_endo = epochs['attention_type_block==1'].copy()\n",
    "\n",
    "# Simplify metadata\n",
    "epochs_endo.metadata['flicker_sides'] = epochs_endo.metadata['flicker_sides'].replace({0: 6064, 1: 6460})\n",
    "epochs_endo.metadata['cued_side'] = epochs_endo.metadata['cued_side'].replace({0: 'left', 1: 'right'})\n",
    "\n",
    "condition_1 = ((epochs_endo.metadata['flicker_sides'] == 6064.0) & (epochs_endo.metadata['cued_side'] == 'left')) | \\\n",
    "    ((epochs_endo.metadata['flicker_sides'] == 6460.0) & (epochs_endo.metadata['cued_side'] == 'right'))\n",
    "condition_2 = ((epochs_endo.metadata['flicker_sides'] == 6064.0) & (epochs_endo.metadata['cued_side'] == 'right')) | \\\n",
    "    ((epochs_endo.metadata['flicker_sides'] == 6460.0) & (epochs_endo.metadata['cued_side'] == 'left'))\n",
    "epochs_endo.metadata['cued_tag'] = np.where(condition_1, 60, np.where(condition_2, 64, np.nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10ba7371-1e08-48b9-a7df-720c162d549c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'used_nei' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 83\u001b[0m\n\u001b[1;32m     79\u001b[0m     used_nei \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m((\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m-\u001b[39m bin_size\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m bin_size)  \u001b[38;5;66;03m# Total bins within ±2 Hz\u001b[39;00m\n\u001b[1;32m     80\u001b[0m     used_nei \u001b[38;5;241m=\u001b[39m used_nei \u001b[38;5;241m-\u001b[39m skip_nei \u001b[38;5;66;03m# Bins within (0.5 Hz, 2 Hz]\u001b[39;00m\n\u001b[0;32m---> 83\u001b[0m snrs \u001b[38;5;241m=\u001b[39m snr_spectrum(psds, noise_n_neighbor_freqs\u001b[38;5;241m=\u001b[39m used_nei, noise_skip_neighbor_freqs \u001b[38;5;241m=\u001b[39m skip_nei)\n\u001b[1;32m     86\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     87\u001b[0m fig, axes \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, sharex\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m, sharey\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'used_nei' is not defined"
     ]
    }
   ],
   "source": [
    "# Fast Fourier Transform\n",
    "# adapted from https://mne.tools/dev/auto_tutorials/time-freq/50_ssvep.html\n",
    "\n",
    "sfreq = epochs_endo.info[\"sfreq\"]\n",
    "tmin = 0 # Search in window starting from cue (when SSVEP is expected)\n",
    "tmax = 2\n",
    "fmin = 1.0\n",
    "fmax = 90\n",
    "\n",
    "# Spectrum of the signal averaged over trials\n",
    "spectrum = epochs_endo.copy().average().compute_psd(\n",
    "    \"welch\",\n",
    "    n_fft=int(sfreq * (tmax - tmin)),\n",
    "    n_overlap=0,\n",
    "    n_per_seg=None,\n",
    "    tmin=tmin,\n",
    "    tmax=tmax,\n",
    "    fmin=fmin,\n",
    "    fmax=fmax,\n",
    "    window=\"hamming\",\n",
    "    verbose=False,\n",
    ")\n",
    "psds, freqs_psd = spectrum.get_data(return_freqs=True)\n",
    "\n",
    "# Signal to noise ratio (Meigen & Bach (1999))\n",
    "\n",
    "def snr_spectrum(psd, noise_n_neighbor_freqs=1, noise_skip_neighbor_freqs=1):\n",
    "    \"\"\"Compute SNR spectrum from PSD spectrum using convolution.\n",
    "    Parameters\n",
    "    ----------\n",
    "    psd : ndarray, shape ([n_trials, n_channels,] n_frequency_bins)\n",
    "        Data object containing PSD values. Works with arrays as produced by\n",
    "        MNE's PSD functions or channel/trial subsets.\n",
    "    noise_n_neighbor_freqs : int\n",
    "        Number of neighboring frequencies used to compute noise level.\n",
    "        increment by one to add one frequency bin ON BOTH SIDES\n",
    "    noise_skip_neighbor_freqs : int\n",
    "        set this >=1 if you want to exclude the immediately neighboring\n",
    "        frequency bins in noise level calculation\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    snr : ndarray, shape ([n_trials, n_channels,] n_frequency_bins)\n",
    "        Array containing SNR for all epochs, channels, frequency bins.\n",
    "        NaN for frequencies on the edges, that do not have enough neighbors on\n",
    "        one side to calculate SNR.\n",
    "    \"\"\"\n",
    "    # Construct a kernel that calculates the mean of the neighboring\n",
    "    # frequencies\n",
    "    averaging_kernel = np.concatenate(\n",
    "        (\n",
    "            np.ones(noise_n_neighbor_freqs),\n",
    "            np.zeros(2 * noise_skip_neighbor_freqs + 1),\n",
    "            np.ones(noise_n_neighbor_freqs),\n",
    "        )\n",
    "    )\n",
    "    averaging_kernel /= averaging_kernel.sum()\n",
    "\n",
    "    # Calculate the mean of the neighboring frequencies by convolving with the\n",
    "    # averaging kernel.\n",
    "    mean_noise = np.apply_along_axis(\n",
    "        lambda psd_: np.convolve(psd_, averaging_kernel, mode=\"valid\"), axis=-1, arr=psd\n",
    "    )\n",
    "\n",
    "    # The mean is not defined on the edges so we will pad it with nas. The\n",
    "    # padding needs to be done for the last dimension only so we set it to\n",
    "    # (0, 0) for the other ones.\n",
    "    edge_width = noise_n_neighbor_freqs + noise_skip_neighbor_freqs\n",
    "    pad_width = [(0, 0)] * (mean_noise.ndim - 1) + [(edge_width, edge_width)]\n",
    "    mean_noise = np.pad(mean_noise, pad_width=pad_width, constant_values=np.nan)\n",
    "\n",
    "    return psd / mean_noise\n",
    "\n",
    "# Get bins to exlude from regularization (close neighbors ±0.5Hz)  \n",
    "bin_size = np.diff(freqs_psd)[0]\n",
    "skip_nei = int((0.5 - bin_size/2)//bin_size) \n",
    "\n",
    "# Get bins to include in regularization (neighbors within +/- 2-0.5Hz)\n",
    "used_nei = int((2 - bin_size/2) // bin_size)  # Total bins within ±2 Hz\n",
    "used_nei = used_nei - skip_nei # Bins within (0.5 Hz, 2 Hz]\n",
    "\n",
    "\n",
    "snrs = snr_spectrum(psds, noise_n_neighbor_freqs= used_nei, noise_skip_neighbor_freqs = skip_nei)\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "fig, axes = plt.subplots(2, 1, sharex=\"all\", sharey=\"none\", figsize=(8, 5))\n",
    "freq_range = range(\n",
    "    np.where(np.floor(freqs_psd) == 1.0)[0][0], np.where(np.ceil(freqs_psd) == fmax - 1)[0][0]\n",
    ")\n",
    "\n",
    "psds_plot = 10 * np.log10(psds)\n",
    "psds_mean = psds_plot.mean(axis=(0))[freq_range]\n",
    "psds_std = psds_plot.std(axis=(0))[freq_range]\n",
    "axes[0].plot(freqs_psd[freq_range], psds_mean, color=\"b\")\n",
    "axes[0].fill_between(\n",
    "    freqs_psd[freq_range], psds_mean - psds_std, psds_mean + psds_std, color=\"b\", alpha=0.2\n",
    ")\n",
    "axes[0].set(title=\"PSD spectrum\", ylabel=\"Power Spectral Density [dB]\")\n",
    "\n",
    "# SNR spectrum\n",
    "snr_mean = snrs.mean(axis=(0))[freq_range]\n",
    "snr_std = snrs.std(axis=(0))[freq_range]\n",
    "\n",
    "axes[1].plot(freqs_psd[freq_range], snr_mean, color=\"r\")\n",
    "axes[1].fill_between(\n",
    "    freqs_psd[freq_range], snr_mean - snr_std, snr_mean + snr_std, color=\"r\", alpha=0.2\n",
    ")\n",
    "axes[1].set(\n",
    "    title=\"SNR spectrum\",\n",
    "    xlabel=\"Frequency [Hz]\",\n",
    "    ylabel=\"SNR\",\n",
    "    ylim=[-2, 30],\n",
    "    xlim=[fmin, fmax],\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# Extract SNR values at the stimulation frequency\n",
    "stim_freq1 = 60\n",
    "stim_freq2 = 64\n",
    "\n",
    "# find index of frequency bin closest to stimulation frequency\n",
    "i_bin_1 = np.argmin(abs(freqs_psd - stim_freq1))\n",
    "i_bin_2 = np.argmin(abs(freqs_psd - stim_freq2))\n",
    "\n",
    "# Apply the subset\n",
    "snrs_target1 = snrs[:, i_bin_1]\n",
    "snrs_target2 = snrs[:, i_bin_2]\n",
    "print(f'SNR at {stim_freq1}Hz: {snrs_target1.mean()}')\n",
    "print(f'SNR at {stim_freq2}Hz: {snrs_target2.mean()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd488652-e122-4059-8212-5cb221332209",
   "metadata": {},
   "source": [
    "## 1.2 Topography of the SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80af327-19d9-441c-9e4f-cd8e1b4b30f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot SNR topography\n",
    "fig, ax = plt.subplots(1)\n",
    "mne.viz.plot_topomap(snrs_target1, epochs.info, vlim=(1, None), axes=ax, extrapolate='local')\n",
    "fig.show()\n",
    "fig, ax = plt.subplots(1)\n",
    "mne.viz.plot_topomap(snrs_target2, epochs.info, vlim=(1, None), axes=ax, extrapolate='local')\n",
    "fig.show()\n",
    "\n",
    "# Channels with the highest SNR \n",
    "print(f'Channels with highest SNR for 60Hz{np.array(epochs.info['ch_names'])[np.argsort(snrs_target1)[::-1]][:6]}')\n",
    "print(f'Channels with highest SNR for 64Hz{np.array(epochs.info['ch_names'])[np.argsort(snrs_target2)[::-1]][:6]}')\n",
    "\n",
    "\n",
    "#select electrodes from 60 as the top electrodes are parietal and occipital\n",
    "SNR_best_electrodes_60 = np.array(epochs.info['ch_names'])[np.argsort(snrs_target1)[::-1]][:6]\n",
    "SNR_best_electrodes_64 = np.array(epochs.info['ch_names'])[np.argsort(snrs_target2)[::-1]][:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3ebda9-b282-4f22-ab75-4aa1eb2ece54",
   "metadata": {},
   "source": [
    "## 1.3 Time frequency analysis of coherence by electrode\n",
    "Coherence is studied in the time window between trial start and onset of the stimuli (the post stimuli window is likely contaminated by attentional catching due to their onset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a176185-4dd8-4477-a6c4-554822543bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time window from -1 sec to 1 sec relative to cue\n",
    "tmin, tmax = -1, 1\n",
    "# Define range of frequencies of interest\n",
    "freqs = np.arange(55, 75, step = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1e864d-be21-40ca-ad1f-9bdcbd43d094",
   "metadata": {},
   "source": [
    "### Magnitude squared coherence with Hilbert transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8231e6c5-8855-4720-94ee-9e768f01bdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coherence_kabir(signalX, pick, freq_of_interest):\n",
    "\n",
    "    #get info from EEG\n",
    "    min_time = signalX.times[0]\n",
    "    max_time = signalX.times[-1]\n",
    "    sampling_rate = signalX.info['sfreq']\n",
    "    \n",
    "    # Band-pass EEG (+/-1.9Hz) and apply hilbert\n",
    "    signalX = signalX.copy().pick(pick).filter(l_freq=freq_of_interest - 1.9, h_freq=freq_of_interest + 1.9,\n",
    "        method='iir', iir_params=dict(order=4, ftype='butter'), phase='zero', fir_window='hamming', verbose = False)\n",
    "    #filter(l_freq = freq_of_interest - 1.9, h_freq = freq_of_interest + 1.9, verbose=True)\n",
    "    \n",
    "    signalX = np.squeeze(signalX.get_data(copy=False)).T\n",
    "    signalXh =  scipy.signal.hilbert(signalX, axis=1)\n",
    "    n = signalXh.shape[1]  # number of trials\n",
    "\n",
    "    #Create sine wave\n",
    "    t = np.linspace(min_time, max_time, int(sampling_rate * (np.abs(min_time) + max_time))+1, endpoint=False)\n",
    "    signalY = np.sin(2 * np.pi * freq_of_interest * t)\n",
    "    signalY = np.tile(signalY, (n,1)).T #repeat over trials\n",
    "    # Hilbert transform\n",
    "    signalYh = scipy.signal.hilbert(signalY.T, axis=1)\n",
    "\n",
    "    # Magnitude\n",
    "    mX = np.abs(signalXh).T\n",
    "    mY = np.abs(signalYh)\n",
    "\n",
    "    # Phase difference\n",
    "    phase_diff = np.angle(signalXh).T - np.angle(signalYh)\n",
    "\n",
    "    coh = np.zeros(signalY.shape[0])\n",
    "    for t in range(signalY.shape[0]):\n",
    "        num = ((np.abs(np.sum(mX[:, t] * mY[:, t] * np.exp(1j * phase_diff[:, t])) / n)) ** 2)\n",
    "        denom = (np.sum((mX[:, t]**2) * (mY[:, t]**2)) / n)\n",
    "        coh[t] = num/denom\n",
    "        \n",
    "    return coh\n",
    "\n",
    "# time window from -1 sec to 1 sec relative to cue\n",
    "tmin, tmax = -1, 1\n",
    "# Define range of frequencies of interest\n",
    "freqs = np.arange(55, 75, step = 0.5)\n",
    "\n",
    "channels = epochs_endo.info['ch_names']\n",
    "\n",
    "epochs_endo_cropped = epochs_endo.copy().crop(tmin, tmax)\n",
    "\n",
    "coherence_mat = np.zeros((len(channels), freqs.size, len(epochs_endo_cropped.times)))\n",
    "\n",
    "for e, channel in enumerate(channels):\n",
    "    for i, freq in enumerate(freqs):\n",
    "        coherence_mat[e,i,:] = coherence_kabir(epochs_endo_cropped, [channel], freq)\n",
    "\n",
    "coherence_hilbert = mne.time_frequency.EpochsTFRArray(epochs_endo_cropped.info, np.array([coherence_mat]), epochs_endo_cropped.times, freqs)\n",
    "\n",
    "# Baseline (-1 to 0s) correction\n",
    "coherence_hilbert = coherence_hilbert.apply_baseline(baseline=(tmin, 0))\n",
    "\n",
    "fig, axes = plt.subplots(3, 6, figsize=(18, 6))  \n",
    "axes = axes.flatten() \n",
    "\n",
    "# Plot each channel\n",
    "for e, (channel, ax) in enumerate(zip(channels, axes)):\n",
    "    coherence_hilbert.plot(\n",
    "        picks=[channel],\n",
    "        baseline= None,\n",
    "        axes=ax,\n",
    "        colorbar=False,\n",
    "        show=False \n",
    "    )\n",
    "    ax.set_title(channel)  \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Channels with the highest coherence with the cued frequency\n",
    "print(f'From best to 5th \\nChannels with the highest coherence with 60:{np.array(epochs.info['ch_names'])[np.argsort(np.squeeze(coherence_mat[:,np.where(freqs == 60),:].max(axis = -1)))[::-1]][:6]} \\\n",
    "                        \\nChannels with the highest coherence with 64:{np.array(epochs.info['ch_names'])[np.argsort(np.squeeze(coherence_mat[:,np.where(freqs == 64),:].max(axis = -1)))[::-1]][:6]}')\n",
    "best_electrodes_coherence_60 = np.array(epochs.info['ch_names'])[np.argsort(np.squeeze(coherence_mat[:,np.where(freqs == 60),:].max(axis = -1)))[::-1]][:6]\n",
    "best_electrodes_coherence_64 = np.array(epochs.info['ch_names'])[np.argsort(np.squeeze(coherence_mat[:,np.where(freqs == 64),:].max(axis = -1)))[::-1]][:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a932b002-5662-4f66-a114-282c5ac39748",
   "metadata": {},
   "source": [
    "### Inter-trial coherence with Morlet estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f02677-d8d1-4185-a72b-661a50503ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_cylce: trade-off temporal vs frequency resolution (is how many cycles of the frequency to include in the Gaussian envelope). \n",
    "# Frequency resolution is emphasized.\n",
    "\n",
    "# time window from -1 sec to 1 sec relative to cue\n",
    "tmin, tmax = -1, 1\n",
    "# Define range of frequencies of interest\n",
    "freqs = np.arange(55, 75, step = 0.5)\n",
    "\n",
    "_, itc = epochs_endo.copy().crop(tmin, tmax).compute_tfr(\n",
    "    method=\"morlet\", freqs=freqs, n_cycles=freqs, return_itc=True, average=True\n",
    ")\n",
    "\n",
    "# Baseline (-1 to 0s) correction\n",
    "itc = itc.apply_baseline(baseline=(tmin, 0))\n",
    "\n",
    "fig, axes = plt.subplots(3, 6, figsize=(18, 9), sharey = True) \n",
    "axes = axes.flatten() \n",
    "\n",
    "channels = epochs_endo.info['ch_names']\n",
    "\n",
    "# Plot each electrode\n",
    "for e, (channel, ax) in enumerate(zip(channels, axes)):\n",
    "    itc.plot(\n",
    "        picks=[channel],\n",
    "        baseline=None,\n",
    "        vlim=(-.4, .4),\n",
    "        axes=ax,\n",
    "        colorbar=False,\n",
    "        show=False \n",
    "    )\n",
    "    ax.set_title(channel) \n",
    "    ax.axhline(y=60, color='r', linestyle='--', linewidth=1)\n",
    "    ax.axhline(y=64, color='r', linestyle='--', linewidth=1)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check whether the expected frequencies are indeed the highest\n",
    "itc_arr, frex_idx = itc.get_data(return_freqs=True)\n",
    "print(f'Frequencies with the maximum coherence in descending order : {frex_idx[itc_arr.mean(axis=(0,2)).argsort()[::-1]][:4]}')\n",
    "\n",
    "print(f'From best to 6th \\nChannels with the highest coherence with 64:{np.array(epochs.info['ch_names'])[np.argsort(np.squeeze(itc_arr[:,np.where(frex_idx==60),:].max(axis = -1)))[::-1]][:6]} \\\n",
    "                        \\nChannels with the highest coherence with 60:{np.array(epochs.info['ch_names'])[np.argsort(np.squeeze(itc_arr[:,np.where(frex_idx==64),:].max(axis = -1)))[::-1]][:6]}')\n",
    "\n",
    "best_electrodes_coherence_morlet_60 = np.array(epochs.info['ch_names'])[np.argsort(np.squeeze(itc_arr[:,np.where(frex_idx==60),:].max(axis = -1)))[::-1]][:6]\n",
    "best_electrodes_coherence_morlet_64 = np.array(epochs.info['ch_names'])[np.argsort(np.squeeze(itc_arr[:,np.where(frex_idx==64),:].max(axis = -1)))[::-1]][:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dfea1f-47c4-4a0f-a325-48efe7809a26",
   "metadata": {},
   "source": [
    "## 1.4 Select electrodes based on previous analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee94e6a1-b23a-4e6c-a08f-98cbf4bf392c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Top 6 electrodes for SNR 60{SNR_best_electrodes_60}')\n",
    "print(f'Top 6 electrodes for SNR 64{SNR_best_electrodes_64}')\n",
    "print(f'Top 6 electrodes for Coherence 60 {best_electrodes_coherence_60}')\n",
    "print(f'Top 6 electrodes for Coherence 64 {best_electrodes_coherence_64}')\n",
    "print(f'Top 6 electrodes for ITC Morlet 60 {best_electrodes_coherence_morlet_60}')\n",
    "print(f'Top 6 electrodes for ITC Morlet 64 {best_electrodes_coherence_morlet_64}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9150ab6-ee4b-4d5e-893b-2d1a7a6c4847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top 6 electrodes that are the most often the best according to SNR, IT coherence and MS coherence\n",
    "all_electrodes = (list(SNR_best_electrodes_60) + \n",
    "                  list(SNR_best_electrodes_64) + \n",
    "                  list(best_electrodes_coherence_60) + \n",
    "                  list(best_electrodes_coherence_64) + \n",
    "                  list(best_electrodes_coherence_morlet_60) + \n",
    "                  list(best_electrodes_coherence_morlet_64))\n",
    "\n",
    "# Count the occurrences of each electrode\n",
    "electrode_counts = Counter(all_electrodes)\n",
    "\n",
    "best_electrodes = [electrode for electrode, count in electrode_counts.most_common(6)]\n",
    "\n",
    "print(f'selected electrodes: {best_electrodes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a2a6d6-8b0b-4afb-8276-59145af76197",
   "metadata": {},
   "source": [
    "# 2 - Testing for an attentional effect\n",
    "### Comparing SNR across cued conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27ef2fd-812c-4d35-a4ee-d558ca2284e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\"cued_tag == 60\", \"cued_tag == 64\"]\n",
    "vals = {}\n",
    "stim_freq1 = 60\n",
    "stim_freq2 = 64\n",
    "\n",
    "sfreq = epochs_endo.info['sfreq']\n",
    "tmin = 0 # Search in window starting from cue (when SSVEP is expected)\n",
    "tmax = 2\n",
    "fmin = 1.0\n",
    "fmax = 90.0\n",
    "\n",
    "for query in queries:\n",
    "    # Spectrum averaged over all trials\n",
    "    spectrum = epochs_endo[query].copy().pick(best_electrodes).average().compute_psd(\n",
    "        \"welch\",\n",
    "        n_fft=int(sfreq * (tmax - tmin)),\n",
    "        n_overlap=0,\n",
    "        n_per_seg=None,\n",
    "        tmin=tmin,\n",
    "        tmax=tmax,\n",
    "        fmin=fmin,\n",
    "        fmax=fmax,\n",
    "        window=\"hamming\",\n",
    "        verbose=False,\n",
    "    )\n",
    "    psds, freqs_psd = spectrum.get_data(return_freqs=True)\n",
    "\n",
    "    # Get bins to exlude from regularization (close neighbors ±0.5Hz)  \n",
    "    bin_size = np.diff(freqs_psd)[0]\n",
    "    skip_nei = int((0.5 - bin_size/2)//bin_size) \n",
    "    \n",
    "    # Get bins to include in regularization (neighbors within +/- 2-0.5Hz)\n",
    "    used_nei = int((2 - bin_size/2) // bin_size)  # Total bins within ±2 Hz\n",
    "    used_nei = used_nei - skip_nei # Bins within (0.5 Hz, 2 Hz]\n",
    "    \n",
    "    \n",
    "    snrs = snr_spectrum(psds, noise_n_neighbor_freqs=used_nei, noise_skip_neighbor_freqs = skip_nei)\n",
    "\n",
    "    # find index of frequency bin closest to stimulation frequency\n",
    "    i_bin_1 = np.argmin(abs(freqs_psd - stim_freq1))\n",
    "    i_bin_2 = np.argmin(abs(freqs_psd - stim_freq2))\n",
    "    \n",
    "    # Apply the subset\n",
    "    vals[str(int(stim_freq1))+query] = copy.deepcopy(snrs[:, i_bin_1])\n",
    "    vals[str(int(stim_freq2))+query] = copy.deepcopy(snrs[:, i_bin_2])\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(7,3), sharex=False)\n",
    "for e, elec in enumerate(best_electrodes):\n",
    "    ax[0].plot([0,1], [vals['60cued_tag == 64'][e], vals['60cued_tag == 60'][e]], 'o-', label=elec)\n",
    "    ax[1].plot([0,1], [vals['64cued_tag == 60'][e], vals['64cued_tag == 64'][e]], 'o-', label=elec)\n",
    "\n",
    "ax[0].set_ylabel('SNR at 60Hz')\n",
    "ax[0].set_xticks([0,1], ['Not cued', 'Cued'])\n",
    "ax[0].set_xlim(-.5, 1.5)\n",
    "ax[1].set_xlim(-.5, 1.5)\n",
    "ax[1].set_xticks([0,1], ['Not cued', 'Cued'])\n",
    "ax[1].set_ylabel('SNR at 64Hz')\n",
    "ax[0].set_title('60Hz tag')\n",
    "ax[1].set_title('64Hz tag')\n",
    "plt.legend(bbox_to_anchor=(1,1))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b142c38-445b-493a-b32a-5b8493a90cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "snr_df = pd.DataFrame(vals)\n",
    "snr_df['electrode'] = best_electrodes\n",
    "snr_df = snr_df.melt(id_vars='electrode')\n",
    "snr_df[['freq', 'cued']] = snr_df['variable'].str.split('cued_tag == ', expand=True)\n",
    "snr_df = snr_df.drop('variable', axis=1)\n",
    "snr_df.to_csv('files/B2_snr.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7f025d-dcba-4100-9aea-ad1d079d8aeb",
   "metadata": {},
   "source": [
    "### Comparing inter-trial coherence across cued conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb057878-b7db-445c-9f8b-cff7d140ae50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time window from -1 sec to 1 sec relative to cue\n",
    "tmin, tmax = -1, 1\n",
    "\n",
    "# Get inter-trial coherence with 60 and 64Hz by cued frequency \n",
    "freqs6064 = [60, 64]\n",
    "_, itc_64 = epochs_endo['cued_tag == 64'].copy().crop(tmin, tmax).compute_tfr(\n",
    "    method=\"morlet\", freqs=freqs6064, n_cycles=np.array(freqs6064), return_itc=True, average=True\n",
    ")\n",
    "\n",
    "_, itc_60 = epochs_endo['cued_tag == 60'].copy().crop(tmin, tmax).compute_tfr(\n",
    "    method=\"morlet\", freqs=freqs6064, n_cycles=np.array(freqs6064), return_itc=True, average=True\n",
    ")\n",
    "\n",
    "itc_64_arr, times_coh, freqs_idx = itc_64.get_data(return_freqs = True, return_times = True)\n",
    "itc_60_arr = itc_60.get_data()\n",
    "\n",
    "elec_idx = np.where(np.isin(epochs.info['ch_names'], best_electrodes))[0]\n",
    "\n",
    "coherence = {}\n",
    "coherence['with64_for64cued'] = itc_64_arr[elec_idx,1,:]\n",
    "coherence['with60_for64cued'] = itc_64_arr[elec_idx,0,:]\n",
    "coherence['with64_for60cued'] = itc_60_arr[elec_idx,1,:]\n",
    "coherence['with60_for60cued'] = itc_60_arr[elec_idx,0,:]\n",
    "\n",
    "plt.plot(times_coh, coherence['with64_for64cued'].T - coherence['with64_for60cued'].T, label = best_electrodes)\n",
    "plt.vlines(0,-0.35,0.3, color = 'black')\n",
    "plt.legend()\n",
    "plt.title('Coherence with 64Hz when 64 cued - coherence with 64 when 64 not cued')\n",
    "plt.xlabel('Time from cue')\n",
    "plt.ylabel('Coherence contrast cued/uncued')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(times_coh, coherence['with60_for60cued'].T - coherence['with60_for64cued'].T, label = best_electrodes)\n",
    "plt.vlines(0,-0.35,0.3, color = 'black')\n",
    "plt.legend()\n",
    "plt.title('Coherence with 60Hz when 60 cued - coherence with 60 when 60 not cued')\n",
    "plt.xlabel('Time from cue')\n",
    "plt.ylabel('Coherence contrast cued/uncued')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2621a72-6c61-4d86-9e00-5c1d0d16e12b",
   "metadata": {},
   "source": [
    "????? il semble qu il n y ait d effet attentionnel. En meme t il ne pouvait pas y avoir de target avant 1s et c etait sur car meme pas les gabor presents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b76099-8eb0-40e4-b848-1d0045853d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export for group analysis\n",
    "\n",
    "def pd_coh(coherence_dic, cued, coh_with):\n",
    "    coherence = pd.DataFrame(coherence_dic[f'with{coh_with}_for{cued}cued'])\n",
    "    coherence['channel'] = best_electrodes\n",
    "    coherence['cued'] = cued\n",
    "    coherence['coh_with'] = coh_with\n",
    "    coherence = coherence.melt(id_vars=['channel','cued','coh_with'])\n",
    "    coherence['time'] = coherence['variable']*(1/epochs_endo.info['sfreq']) + tmin\n",
    "    return coherence\n",
    "\n",
    "coh64_cue64 = pd_coh(coherence, 64, 64)\n",
    "coh64_cue60 = pd_coh(coherence, 60, 64)\n",
    "coh60_cue64 = pd_coh(coherence, 64, 60)\n",
    "coh60_cue60 = pd_coh(coherence, 60, 60)\n",
    "\n",
    "ITcoh_B2 = pd.concat([coh60_cue60, coh60_cue64, coh64_cue60, coh64_cue64])\n",
    "ITcoh_B2.columns = ['channel', 'cued', 'coh_with', 'timepoint', 'ITcoherence', 'time']\n",
    "ITcoh_B2.to_csv('files/ITcoh_B2.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9da49bb-ea0f-4c83-8c20-99b874d7ff09",
   "metadata": {},
   "source": [
    "### Comparing MS coherence across cued conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a48613-2270-471d-9fc3-38cd4a34b99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time window from -1 sec to 1 sec relative to cue\n",
    "tmin, tmax = -1, 1\n",
    "# Define range of frequencies of interest\n",
    "freqs = np.array([60, 64])\n",
    "\n",
    "epochs_endo_cropped = epochs_endo['cued_tag == 64'].copy().pick(best_electrodes).crop(tmin, tmax)\n",
    "coherence_mat = np.zeros((len(best_electrodes), freqs.size, len(epochs_endo_cropped.times)))\n",
    "for e, channel in enumerate(best_electrodes):\n",
    "    for i, freq in enumerate(freqs):\n",
    "        coherence_mat[e,i,:] = coherence_kabir(epochs_endo_cropped, [channel], freq)\n",
    "coherence_hilbert_64 = mne.time_frequency.EpochsTFRArray(epochs_endo_cropped.info, np.array([coherence_mat]), epochs_endo_cropped.times, freqs)\n",
    "\n",
    "epochs_endo_cropped = epochs_endo['cued_tag == 60'].copy().pick(best_electrodes).crop(tmin, tmax)\n",
    "coherence_mat = np.zeros((len(best_electrodes), freqs.size, len(epochs_endo_cropped.times)))\n",
    "for e, channel in enumerate(best_electrodes):\n",
    "    for i, freq in enumerate(freqs):\n",
    "        coherence_mat[e,i,:] = coherence_kabir(epochs_endo_cropped, [channel], freq)\n",
    "coherence_hilbert_60 = mne.time_frequency.EpochsTFRArray(epochs_endo_cropped.info, np.array([coherence_mat]), epochs_endo_cropped.times, freqs)\n",
    "\n",
    "coherence_hilbert_64, times_coh, freqs_idx = coherence_hilbert_64.get_data(return_freqs = True, return_times = True)\n",
    "coherence_hilbert_60 = coherence_hilbert_60.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918b0e0f-4c43-4288-a972-c56255c2751b",
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_hilbert = {}\n",
    "coherence_hilbert['with64_for64cued'] = np.squeeze(coherence_hilbert_64)[:,1,:]\n",
    "coherence_hilbert['with60_for64cued'] = np.squeeze(coherence_hilbert_64)[:,0,:]\n",
    "coherence_hilbert['with64_for60cued'] = np.squeeze(coherence_hilbert_60)[:,1,:]\n",
    "coherence_hilbert['with60_for60cued'] = np.squeeze(coherence_hilbert_60)[:,0,:]\n",
    "\n",
    "plt.plot(times_coh, coherence_hilbert['with64_for64cued'].T - coherence_hilbert['with64_for60cued'].T, label = best_electrodes)\n",
    "plt.vlines(0,-0.35,0.3, color = 'black')\n",
    "plt.legend()\n",
    "plt.title('Coherence with 64Hz when 64 cued - coherence with 64 when 64 not cued')\n",
    "plt.xlabel('Time from cue')\n",
    "plt.ylabel('Coherence contrast cued/uncued')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(times_coh, coherence_hilbert['with60_for60cued'].T - coherence_hilbert['with60_for64cued'].T, label = best_electrodes)\n",
    "plt.vlines(0,-0.35,0.3, color = 'black')\n",
    "plt.legend()\n",
    "plt.title('Coherence with 60Hz when 60 cued - coherence with 60 when 60 not cued')\n",
    "plt.xlabel('Time from cue')\n",
    "plt.ylabel('Coherence contrast cued/uncued')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa79dce0-c9fb-4a05-bb38-64519142d56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export for group analysis\n",
    "coh64_cue64 = pd_coh(coherence_hilbert, 64, 64)\n",
    "coh64_cue60 = pd_coh(coherence_hilbert, 60, 64)\n",
    "coh60_cue64 = pd_coh(coherence_hilbert, 64, 60)\n",
    "coh60_cue60 = pd_coh(coherence_hilbert, 60, 60)\n",
    "\n",
    "MScoh_B2 = pd.concat([coh60_cue60, coh60_cue64, coh64_cue60, coh64_cue64])\n",
    "MScoh_B2.columns = ['channel', 'cued', 'coh_with', 'timepoint', 'MScoherence', 'time']\n",
    "MScoh_B2.to_csv('files/MScoh_B2.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
